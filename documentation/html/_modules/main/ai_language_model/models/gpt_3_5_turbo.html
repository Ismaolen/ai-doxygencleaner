<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>main.ai_language_model.models.gpt_3_5_turbo &#8212; AI-DoxygenCleaner  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/alabaster.css" />
    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/sphinx_highlight.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for main.ai_language_model.models.gpt_3_5_turbo</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">re</span>

<span class="kn">from</span> <span class="nn">ai_language_model.ai_language_model</span> <span class="kn">import</span> <span class="n">AILanguageModel</span>
<span class="kn">import</span> <span class="nn">openai</span>
<span class="kn">import</span> <span class="nn">tiktoken</span>


<div class="viewcode-block" id="GPT3_5TurboModel"><a class="viewcode-back" href="../../../../main.ai_language_model.models.html#main.ai_language_model.models.gpt_3_5_turbo.GPT3_5TurboModel">[docs]</a><span class="k">class</span> <span class="nc">GPT3_5TurboModel</span><span class="p">(</span><span class="n">AILanguageModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This class extends the AILanguageModel class and is specifically designed to</span>
<span class="sd">    handle interaction with the GPT-3.5 Turbo model provided by OpenAI. It enables</span>
<span class="sd">    communication with the model, formatting and validation of the responses, and</span>
<span class="sd">    also contains utility functions for token counting and line removal.</span>
<span class="sd">    ...</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    __api_key : str</span>
<span class="sd">        The OpenAI API key used to authenticate requests to the API.</span>

<span class="sd">    Methods</span>
<span class="sd">    ----------</span>
<span class="sd">    _create_response(prompt_content):</span>
<span class="sd">        Creates a response from the GPT-3.5 Turbo model using the given prompt content.</span>
<span class="sd">    validate_response_content():</span>
<span class="sd">        Validates the content of the model&#39;s response and performs necessary modifications.</span>
<span class="sd">    set_response_content():</span>
<span class="sd">        Sets the processed content of the model&#39;s response.</span>
<span class="sd">    get_num_tokens_from_response(string: str, encoding_name: str) -&gt; int:</span>
<span class="sd">        Counts the number of tokens in a given string.</span>
<span class="sd">    remove_back_quote():</span>
<span class="sd">        Removes backquote encapsulated strings from the model&#39;s response.</span>
<span class="sd">    remove_cpp_directives():</span>
<span class="sd">        Removes C++ directive lines from the model&#39;s response.</span>
<span class="sd">    remove_unwanted_line():</span>
<span class="sd">        Removes unwanted lines from the model&#39;s response.</span>
<span class="sd">    _set_api_key(self, api_key):</span>

<span class="sd">    set_prompt_input_str(self, prompt_input_str):</span>

<span class="sd">    set_prompt_instruction(self, prompt_instruction):</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt_instruction</span><span class="p">,</span> <span class="n">prompt_input_str</span><span class="p">,</span> <span class="n">api_key</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Constructs all the necessary attributes for the GPT3_5TurboModel object.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        prompt_instruction : str</span>
<span class="sd">            The instruction to guide the language model&#39;s response.</span>
<span class="sd">        prompt_input_str : str</span>
<span class="sd">            The initial string input for the language model.</span>
<span class="sd">        api_key : str</span>
<span class="sd">            The OpenAI API key to be used for making API requests.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">prompt_instruction</span><span class="p">,</span> <span class="n">prompt_input_str</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span> <span class="o">=</span> <span class="n">api_key</span>

    <span class="k">def</span> <span class="nf">_set_api_key</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">api_key</span><span class="p">):</span>
        <span class="c1"># Setting the OpenAI API key for requests</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span> <span class="o">=</span> <span class="n">api_key</span>
        <span class="n">openai</span><span class="o">.</span><span class="n">api_key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__api_key</span>

<div class="viewcode-block" id="GPT3_5TurboModel.set_prompt_input_str"><a class="viewcode-back" href="../../../../main.ai_language_model.models.html#main.ai_language_model.models.gpt_3_5_turbo.GPT3_5TurboModel.set_prompt_input_str">[docs]</a>    <span class="k">def</span> <span class="nf">set_prompt_input_str</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt_input_str</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prompt_input_str</span> <span class="o">=</span> <span class="n">prompt_input_str</span></div>

<div class="viewcode-block" id="GPT3_5TurboModel.set_prompt_instruction"><a class="viewcode-back" href="../../../../main.ai_language_model.models.html#main.ai_language_model.models.gpt_3_5_turbo.GPT3_5TurboModel.set_prompt_instruction">[docs]</a>    <span class="k">def</span> <span class="nf">set_prompt_instruction</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt_instruction</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prompt_instruction</span> <span class="o">=</span> <span class="n">prompt_instruction</span></div>

    <span class="k">def</span> <span class="nf">_create_response</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prompt_content</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calls the OpenAI API and generates a response using the GPT-3.5 Turbo model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        prompt_content : str</span>
<span class="sd">            Content of the language model prompt.</span>

<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        1. OpenAI. (no date). API Documentation: Making Requests. OpenAI Platform. Available at:</span>
<span class="sd">            https://platform.openai.com/docs/api-reference/making-requests. Accessed on July 8, 2023.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Create a message that consists of the role (user) and content</span>
        <span class="c1"># (input string = prompt_instruction + prompt_input_str )</span>
        <span class="c1"># Configure the model parameters such as temperature, top_p, frequency_penalty,</span>
        <span class="c1"># and presence_penalty The response from the model is stored in self.response</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_response</span> <span class="o">=</span> <span class="n">openai</span><span class="o">.</span><span class="n">ChatCompletion</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
            <span class="c1"># model=&quot;gpt-3.5-turbo-0613&quot;,</span>
            <span class="n">model</span><span class="o">=</span><span class="s2">&quot;gpt-3.5-turbo-0613&quot;</span><span class="p">,</span>
            <span class="n">messages</span><span class="o">=</span><span class="p">[</span>
                <span class="p">{</span><span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span> <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="n">prompt_content</span><span class="p">}</span>
            <span class="p">],</span>
            <span class="n">temperature</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
            <span class="n">top_p</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
            <span class="n">frequency_penalty</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
            <span class="n">presence_penalty</span><span class="o">=</span><span class="mf">0.5</span>
        <span class="p">)</span>

<div class="viewcode-block" id="GPT3_5TurboModel.validate_response_content"><a class="viewcode-back" href="../../../../main.ai_language_model.models.html#main.ai_language_model.models.gpt_3_5_turbo.GPT3_5TurboModel.validate_response_content">[docs]</a>    <span class="k">def</span> <span class="nf">validate_response_content</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Validates the content of the model&#39;s response and performs necessary modifications like removing backquotes and</span>
<span class="sd">        unwanted lines, and C++ directives.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Performing validation and modification operations on the response content</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">remove_back_quote</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">remove_unwanted_line</span><span class="p">()</span></div>
        <span class="c1"># self.remove_cpp_directives()</span>

<div class="viewcode-block" id="GPT3_5TurboModel.set_response_content"><a class="viewcode-back" href="../../../../main.ai_language_model.models.html#main.ai_language_model.models.gpt_3_5_turbo.GPT3_5TurboModel.set_response_content">[docs]</a>    <span class="k">def</span> <span class="nf">set_response_content</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Sets the content of the model&#39;s response by extracting the relevant portion</span>
<span class="sd">        from the model&#39;s response.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># The &#39;content&#39; key from the &#39;message&#39; dictionary of the first choice from the &#39;choices&#39; list</span>
        <span class="c1"># in the response is extracted and set as the response_content</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">response_content</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_response</span><span class="p">[</span><span class="s1">&#39;choices&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;message&#39;</span><span class="p">][</span><span class="s1">&#39;content&#39;</span><span class="p">]</span></div>

<div class="viewcode-block" id="GPT3_5TurboModel.get_num_tokens_from_response"><a class="viewcode-back" href="../../../../main.ai_language_model.models.html#main.ai_language_model.models.gpt_3_5_turbo.GPT3_5TurboModel.get_num_tokens_from_response">[docs]</a>    <span class="k">def</span> <span class="nf">get_num_tokens_from_response</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">string</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">encoding_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Counts the number of tokens in a given string using OpenAI&#39;s tiktoken library.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        string : str</span>
<span class="sd">            The string from which tokens are to be counted.</span>
<span class="sd">        encoding_name : str</span>
<span class="sd">            The name of the encoding method to be used for token counting.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int</span>
<span class="sd">            The number of tokens in the input string.</span>

<span class="sd">        openai-cookbook/examples</span>
<span class="sd">        References</span>
<span class="sd">        ----------</span>
<span class="sd">        1. OpenAI Cookbook. (no date). How to count tokens with tiktoken. GitHub. Available at:</span>
<span class="sd">            https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb</span>
<span class="sd">            Accessed on July 8, 2023.</span>
<span class="sd">        2. OpenAI. (no date). tiktoken. GitHub. Available at:</span>
<span class="sd">            https://github.com/openai/tiktoken/blob/main/tiktoken/model.py Accessed on July 8, 2023.</span>
<span class="sd">        3. OpenAI. (no date). Tokenizer. OpenAI Platform. Ac Available at:</span>
<span class="sd">            https://platform.openai.com/tokenizer Accessed on July 8, 2023.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">encoding</span> <span class="o">=</span> <span class="n">tiktoken</span><span class="o">.</span><span class="n">encoding_for_model</span><span class="p">(</span><span class="n">encoding_name</span><span class="p">)</span>
        <span class="n">num_tokens</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">encoding</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">string</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">num_tokens</span></div>

<div class="viewcode-block" id="GPT3_5TurboModel.remove_back_quote"><a class="viewcode-back" href="../../../../main.ai_language_model.models.html#main.ai_language_model.models.gpt_3_5_turbo.GPT3_5TurboModel.remove_back_quote">[docs]</a>    <span class="k">def</span> <span class="nf">remove_back_quote</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Removes lines containing backquote encapsulated strings from the model&#39;s response.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Split the response content into separate lines</span>
        <span class="n">lines</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">response_content</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Remove any line that contains the &#39;```cpp&#39; or &#39;```&#39; string</span>
        <span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">line</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span> <span class="k">if</span> <span class="s2">&quot;```cpp&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">line</span> <span class="ow">and</span> <span class="s2">&quot;```&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">line</span><span class="p">]</span>

        <span class="c1"># Join the remaining lines back into a single string and set it as the response content</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">response_content</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">lines</span><span class="p">)</span></div>

<div class="viewcode-block" id="GPT3_5TurboModel.remove_cpp_directives"><a class="viewcode-back" href="../../../../main.ai_language_model.models.html#main.ai_language_model.models.gpt_3_5_turbo.GPT3_5TurboModel.remove_cpp_directives">[docs]</a>    <span class="k">def</span> <span class="nf">remove_cpp_directives</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Removes C++ directive lines from the model&#39;s response.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># List of C++ directives to be removed</span>
        <span class="n">cpp_directives</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;#ifndef&#39;</span><span class="p">,</span> <span class="s1">&#39;#define&#39;</span><span class="p">,</span> <span class="s1">&#39;#endif&#39;</span><span class="p">]</span>

        <span class="c1"># Split the response content into separate lines</span>
        <span class="n">lines</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">response_content</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="c1"># Remove any line that starts with a C++ directive</span>
        <span class="n">cleaned_lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">line</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span> <span class="k">if</span>
                         <span class="ow">not</span> <span class="nb">any</span><span class="p">(</span><span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">directive</span><span class="p">)</span> <span class="k">for</span> <span class="n">directive</span> <span class="ow">in</span> <span class="n">cpp_directives</span><span class="p">)]</span>

        <span class="c1"># Join the remaining lines back into a single string and set it as the response content</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">response_content</span> <span class="o">=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cleaned_lines</span><span class="p">)</span></div>

<div class="viewcode-block" id="GPT3_5TurboModel.remove_unwanted_line"><a class="viewcode-back" href="../../../../main.ai_language_model.models.html#main.ai_language_model.models.gpt_3_5_turbo.GPT3_5TurboModel.remove_unwanted_line">[docs]</a>    <span class="k">def</span> <span class="nf">remove_unwanted_line</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Removes unwanted lines from the model&#39;s response using regex in multiline mode for better efficiency.</span>
<span class="sd">        Further details and examples can be found in /utils/runtime_measurement.py.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Define a list of phrases that, if they appear at the start of a line, mean the line should be removed.</span>
        <span class="c1"># This centralizes the unwanted phrases, making it easier to manage and update them in the future.</span>
        <span class="n">unwanted_start_phrases</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s1">&#39;Please&#39;</span><span class="p">,</span> <span class="s1">&#39;I have added&#39;</span><span class="p">,</span> <span class="s1">&#39;Explanation:&#39;</span><span class="p">,</span> <span class="s1">&#39;\. Added&#39;</span><span class="p">,</span> <span class="s1">&#39;\. Fixed&#39;</span><span class="p">,</span> <span class="s1">&#39;\. Documented&#39;</span><span class="p">,</span>
            <span class="s1">&#39;- Added&#39;</span><span class="p">,</span> <span class="s1">&#39;- Fixed&#39;</span><span class="p">,</span> <span class="s1">&#39;- Documented&#39;</span><span class="p">,</span> <span class="s1">&#39;- Line&#39;</span><span class="p">,</span> <span class="s1">&#39;- Provided&#39;</span><span class="p">,</span> <span class="s1">&#39;Note:&#39;</span><span class="p">,</span>
            <span class="s1">&#39;- Used&#39;</span><span class="p">,</span> <span class="s1">&#39;Doxygen-Warnings:&#39;</span><span class="p">,</span> <span class="s1">&#39;Line number:&#39;</span><span class="p">,</span> <span class="s1">&#39;File name:&#39;</span><span class="p">,</span> <span class="s1">&#39;File content:&#39;</span><span class="p">,</span> <span class="s2">&quot;Let&#39;s fix&quot;</span><span class="p">,</span>
            <span class="s1">&#39;The added&#39;</span><span class="p">,</span> <span class="s2">&quot;Sure, I&#39;ll&quot;</span><span class="p">,</span> <span class="s2">&quot;This revised&quot;</span><span class="p">,</span> <span class="s2">&quot;Here&#39;s the&quot;</span><span class="p">,</span> <span class="s2">&quot;The provided&quot;</span><span class="p">,</span> <span class="s1">&#39;I hope&#39;</span><span class="p">,</span> <span class="s1">&#39;Here is&#39;</span>
        <span class="p">]</span>

        <span class="c1"># Construct a regex pattern to match lines that start with any of the unwanted phrases.</span>
        <span class="c1"># The &#39;^&#39; asserts position at the start of a line, and &#39;\s*&#39; matches any whitespace at the beginning of a line.</span>
        <span class="c1"># The &#39;.*\n&#39; matches the rest of the line including the newline character.</span>
        <span class="c1"># Using &#39;|&#39;.join(...) creates a pattern that matches any one of the phrases in the list.</span>
        <span class="n">pattern</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;^\s*(&quot;</span> <span class="o">+</span> <span class="s2">&quot;|&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">unwanted_start_phrases</span><span class="p">)</span> <span class="o">+</span> <span class="sa">r</span><span class="s2">&quot;).*\n?&quot;</span>

        <span class="c1"># Compile the regex pattern for faster execution and enable multiline mode.</span>
        <span class="c1"># The multiline mode makes &#39;^&#39; and &#39;$&#39; match the start/end of each line (not just start/end of the string).</span>
        <span class="n">regex</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">pattern</span><span class="p">,</span> <span class="n">re</span><span class="o">.</span><span class="n">MULTILINE</span><span class="p">)</span>

        <span class="c1"># Use the compiled regex to remove all lines that start with any of the unwanted phrases.</span>
        <span class="c1"># The sub() method replaces lines matching the unwanted phrases with an empty string, removing them.</span>
        <span class="c1"># Finally, strip() removes any extraneous whitespace from the updated content.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">response_content</span> <span class="o">=</span> <span class="n">regex</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">response_content</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span></div></div>
</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../index.html">AI-DoxygenCleaner</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../main.html">main package</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../index.html">Documentation overview</a><ul>
  <li><a href="../../../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, Ismial Al Shuaybi.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.0.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
    </div>

    

    
  </body>
</html>